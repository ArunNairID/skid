Simple, plaintext, file system


* Motivation

Great post by GradHacker: [[http://www.gradhacker.org/2012/08/13/towards-better-pdf-management-with-the-filesystem/][Towards Better PDF Management with the Filesystem]].

Tools for organizing your pdfs are restrictive (and proprietary in the sense
that information is kept hostage inside the software).

Article advocates
 1. use file system: helps avoid the "proprietary data problem"
 2. flat structure: keeping a single (flat) directory of all your papers
 3. tags over folders: well-known problem we all faced before gmail.
 4. conventions: naming conventions, tagging conventions
 5. "simple scripts": they don't say it directly (author is a mac user, not a
    linux geek), but they talk about using simple programs rather large
    monolithic programs.

* Explanation

** How is data stored?

Documents (or links to documents) go in cache.

Each document has a directory right next to it, which will hold metadata. For
example.

: cache/
:     somefile.ext
:     somefile.ext.d/
:         bibtex
:         notes.org
:         data/
:             text
:             hash

Now, we can write command-line scripts which will query this data set.

Examples include:

 - keyword search: over the plaintext content or descriptions. This might
   require building an inverted index (only to be super efficient). Grep (or
   preferably [[http://betterthangrep.com/][ack]]) works surprisingly fast and get you most of the way there.

 - metadata: light markup for metadata title, tags, source

 - plaintext: for searching with grep, ack, or whoosh index.

 - information displays: Show we know about a particular file. E.g. title,
   bibtex data, tags, and comments for research papers.


** Adding a document

  1. cache document (download links - it will be cached locally, copy local
     files into =~/.skid/marks= directory)
  2. create =.d= directory
  3. create =notes.org= file (initialize content, e.g. title, tags)
  4. merge with any existing =notes.org=
  5. open description file in a text editor

Merging - what if the document has already been added?

 - anything automatically replaces null.
 - conflict can be dealt with via kdiff3 or possibly some emacs extension.

Keeping data safe

 - TODO: staging area
 - version control

Example description file

: :title: Personal homepage of Tim Vieira
: :source: http://timvieira.github.com
: :tags: people nlp ml
:
: PhD student at Johns Hopkins University. Works on Dyna programming language and
: speeding-up inference algorithms using machine learning.

* Things I fumble about trying to do

 - looking up a paper's directory so that I could copy files into its folder

   - TODO: what about =skid attach <doc> [files+]=?

   - proposed solution: add links to .d and notes.org; a nice terminal will
     makes these clickable links.

 - jumping to =~/.skid= directory (e.g. to check on hg)

   * created alias =skid-dir= (why can't python cd like a bash script?)

   * added =skid hg ...= subcommand.

 - narrowing search: keyword search returns too many results. I want to "pick"
   one paper (pick can mean open, take notes, grab metadata).

   Approaches (not mutually exclusive):

   * ranking: give preference to certain fields like file name, author, title,
     and notes before text.

   * auto-complete/suggestion: (todo: could look at discriminating words between
     results)

   Both approaches should be combined. Auto-complete/suggestion might require an
   interactive command-line interface (or possibly a web app, not sure how I
   feel about a web app).

* Outstanding issues

 - What if I don't want to write notes about a specific single paper, but rather
   on a topic or something ... for example the learn directories...

 - Reference structure:
   - It might be nice to leverage/standardize the way documents /cite/, at least
     in the notes.org file. (I'm pretty sure we want to avoid automatic citation
     extraction)

 - Attachments:
   - maybe single documents is too flat...
   - Should attachments be indexed?

* Markup language

Need to evaluate alternatives here.

org-mode seems to want something like the following for 'proper' metadata

: #+title: Meta-Syntactic Variables
:
: :PROPERTIES:
:   :title: Meta-Syntactic Variables
:   :author: Foo B. Baz
:   :year: 2012
: :END:

This is pretty ugly.. Why do you have to be so 90s org-mode? I love that
org-mode works so well in emacs, but the syntax is not as nice as other markup
languages.


* Ideas for future work

** Misc

- too many tools for messing around with pdfs {pstotext, pdftotext, pdftothtml,
  pdfminer}

- export metadata to org-mode buffer for quick browsing and editing..

** archive/crawl entire webpages, for offline reading and indexing

Sometimes we only get a useless homepage with little or no content.

For example, the 'learn you a haskell for great good!' tutorial, is something
you might want to read offline or index beyond the homepage.

This might be a tought problem... We can try to keep it to really simple wget
options. I've done a few times to download course webpages... Maybe this is just
hoarding...

** Automatic metadata extration

 - author and title classifiers

 - interface/workflow for quickly checking and correcting classifier output.

** Simple heuristics for finding duplicates

** Recommendation

find related stuff, suggest tags

* Thinking out loud

I'm a big fan of the /central directory/ with all my papers in it, but there is
a potential problem that it might cause it to /get out of hand/.

 - I should probably be encouraged to remove duplicates and documents which are
   "useless".

   Version control conventions for deletion might make it very easy to safely
   delete things. For example, if we store the files-hash in a commit message we
   can later grep vc logs for file-hash if we try to add the same document again
   -- allowing us to prompt the user "do you want to resurrect your notes?".

The learn projects is something that I'm have a bit of trouble getting rid of
for a few reasons (1) it's nice to think of these things as "topics" I'd like to
learn about (for the most part hierarchical structures isn't too much of an
issue because topics are pretty flat. There is the occasional: "is this BP or
autodiff?" type of question).

 - I like that learn has references, code, and notes kept together in a single
   directory. This way relevant files are brought to my attention (things which
   I want to /refer to constantly/ and things which are only in my /peripheral/,
   document which have /potential/.

 - TODO: Can we get exactly this same effect by actually USING skid? For
   example, if I want to see files relevant to 'learn/topic' I can simply look
   for documents tagged something like 'learn' and 'topic'. Dumping things in
   skid marks has to disadvantage of 'add' overhead (this can be remedied by
   non-interactive mode; I could even tag documents with system tag like
   '$unsorted' or something like that to indicate that this is potentially just
   some crap I downloaded and want indexed so I can find it later).

   skid-explore could make personalized recommendations, which go beyond the
   learn tagging scheme, and will go beyond the hierarchical folder structure.

   So this means -- papers will not live in learn, but notes and code still will
   for now.

* Extensions

- more data: I believe =skid= is prepared to index more types of text-like data
  including arbitrary notes and emails. The big difference this files frequently
  change, unlike most pdfs.

- information extraction: I'd like to extract authors and avoid repeatedly
  making the same types of mistakes. The ideal setup will include automated
  tests and online learning (e.g. a simple perceptron learner).

* TODO

- utils/gscholar.py looks like a very clever little script! See if we ant to
  plug it into our pipeline.
